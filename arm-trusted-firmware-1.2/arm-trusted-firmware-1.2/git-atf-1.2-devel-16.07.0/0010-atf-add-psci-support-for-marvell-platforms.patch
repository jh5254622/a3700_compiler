From 2cc638a561a2f1648e2a628ea319c4d1157c19cb Mon Sep 17 00:00:00 2001
From: "hayim@marvell.com" <hayim@marvell.com>
Date: Wed, 3 Feb 2016 13:55:03 +0200
Subject: [PATCH 010/239] atf: add psci support for marvell platforms

- add required interfaces for atf build
- migrated marvell (general and a8k specific) code
  for supporting psci

Change-Id: Id218183a7e1a2a0d87a0090dd38efcbd3c470560
Signed-off-by: hayim@marvell.com <hayim@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/27169
---
 include/plat/marvell/common/asm/macro.h       | 264 ++++++++++++++++++++++++++
 plat/marvell/a8k/a7040_rz/aarch64/plat_psci.S | 261 +++++++++++++++++++++++++
 plat/marvell/a8k/a7040_rz/plat_pm.c           | 165 ++++++++++++++++
 plat/marvell/a8k/a7040_rz/plat_topology.c     |  66 +++++++
 plat/marvell/common/aarch64/transition.S      |  57 ++++++
 plat/marvell/common/marvell_pm.c              |  51 +++++
 plat/marvell/common/marvell_topology.c        |  56 ++++++
 7 files changed, 920 insertions(+)
 create mode 100644 include/plat/marvell/common/asm/macro.h
 create mode 100644 plat/marvell/a8k/a7040_rz/aarch64/plat_psci.S
 create mode 100644 plat/marvell/a8k/a7040_rz/plat_pm.c
 create mode 100644 plat/marvell/a8k/a7040_rz/plat_topology.c
 create mode 100644 plat/marvell/common/aarch64/transition.S
 create mode 100644 plat/marvell/common/marvell_pm.c
 create mode 100644 plat/marvell/common/marvell_topology.c

diff --git a/include/plat/marvell/common/asm/macro.h b/include/plat/marvell/common/asm/macro.h
new file mode 100644
index 0000000..e4aeba5
--- /dev/null
+++ b/include/plat/marvell/common/asm/macro.h
@@ -0,0 +1,264 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2016 Marvell International Ltd.
+* ***************************************************************************
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are met:
+*
+* Redistributions of source code must retain the above copyright notice, this
+* list of conditions and the following disclaimer.
+*
+* Redistributions in binary form must reproduce the above copyright notice,
+* this list of conditions and the following disclaimer in the documentation
+* and/or other materials provided with the distribution.
+*
+* Neither the name of Marvell nor the names of its contributors may be used
+* to endorse or promote products derived from this software without specific
+* prior written permission.
+*
+* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+* AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+* IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+* ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+* LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
+* OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+* SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+* INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+* CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+* ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+* POSSIBILITY OF SUCH DAMAGE.
+*
+***************************************************************************
+*/
+/*
+ * include/asm-arm/macro.h
+ *
+ * Copyright (C) 2009 Jean-Christophe PLAGNIOL-VILLARD <plagnioj@jcrosoft.com>
+ *
+ * SPDX-License-Identifier:	GPL-2.0+
+ */
+
+#ifndef __ASM_ARM_MACRO_H__
+#define __ASM_ARM_MACRO_H__
+#ifdef __ASSEMBLY__
+
+/*
+ * These macros provide a convenient way to write 8, 16 and 32 bit data
+ * to any address.
+ * Registers r4 and r5 are used, any data in these registers are
+ * overwritten by the macros.
+ * The macros are valid for any ARM architecture, they do not implement
+ * any memory barriers so caution is recommended when using these when the
+ * caches are enabled or on a multi-core system.
+ */
+
+.macro	write32, addr, data
+	ldr	r4, =\addr
+	ldr	r5, =\data
+	str	r5, [r4]
+.endm
+
+.macro	write16, addr, data
+	ldr	r4, =\addr
+	ldrh	r5, =\data
+	strh	r5, [r4]
+.endm
+
+.macro	write8, addr, data
+	ldr	r4, =\addr
+	ldrb	r5, =\data
+	strb	r5, [r4]
+.endm
+
+/*
+ * This macro generates a loop that can be used for delays in the code.
+ * Register r4 is used, any data in this register is overwritten by the
+ * macro.
+ * The macro is valid for any ARM architeture. The actual time spent in the
+ * loop will vary from CPU to CPU though.
+ */
+
+.macro	wait_timer, time
+	ldr	r4, =\time
+1:
+	nop
+	subs	r4, r4, #1
+	bcs	1b
+.endm
+
+#ifdef CONFIG_ARM64
+/*
+ * Register aliases.
+ */
+lr	.req	x30
+
+/*
+ * Branch according to exception level
+ */
+.macro	switch_el, xreg, el3_label, el2_label, el1_label
+	mrs	\xreg, CurrentEL
+	cmp	\xreg, 0xc
+	b.eq	\el3_label
+	cmp	\xreg, 0x8
+	b.eq	\el2_label
+	cmp	\xreg, 0x4
+	b.eq	\el1_label
+.endm
+
+/*
+ * Branch if current processor is a Cortex-A57 core.
+ */
+.macro	branch_if_a57_core, xreg, a57_label
+	mrs	\xreg, midr_el1
+	lsr	\xreg, \xreg, #4
+	and	\xreg, \xreg, #0x00000FFF
+	cmp	\xreg, #0xD07		/* Cortex-A57 MPCore processor. */
+	b.eq	\a57_label
+.endm
+
+/*
+ * Branch if current processor is a Cortex-A53 core.
+ */
+.macro	branch_if_a53_core, xreg, a53_label
+	mrs	\xreg, midr_el1
+	lsr	\xreg, \xreg, #4
+	and	\xreg, \xreg, #0x00000FFF
+	cmp	\xreg, #0xD03		/* Cortex-A53 MPCore processor. */
+	b.eq	\a53_label
+.endm
+
+/*
+ * Branch if current processor is a slave,
+ * choose processor with all zero affinity value as the master.
+ */
+.macro	branch_if_slave, xreg, slave_label
+	mrs	\xreg, mpidr_el1
+	tst	\xreg, #0xff		/* Test Affinity 0 */
+	b.ne	\slave_label
+	lsr	\xreg, \xreg, #8
+	tst	\xreg, #0xff		/* Test Affinity 1 */
+	b.ne	\slave_label
+	lsr	\xreg, \xreg, #8
+	tst	\xreg, #0xff		/* Test Affinity 2 */
+	b.ne	\slave_label
+	lsr	\xreg, \xreg, #16
+	tst	\xreg, #0xff		/* Test Affinity 3 */
+	b.ne	\slave_label
+.endm
+
+/*
+ * Branch if current processor is a master,
+ * choose processor with all zero affinity value as the master.
+ */
+.macro	branch_if_master, xreg1, xreg2, master_label
+	mrs	\xreg1, mpidr_el1
+	lsr	\xreg2, \xreg1, #32
+	lsl	\xreg1, \xreg1, #40
+	lsr	\xreg1, \xreg1, #40
+	orr	\xreg1, \xreg1, \xreg2
+	cbz	\xreg1, \master_label
+.endm
+
+.macro armv8_switch_to_el2_m, xreg1
+#ifdef CONFIG_ARMV8_PSCI
+	/* 64bit EL2 | HCE | RES1 (Bits[5:4]) | Non-secure EL0/EL1 */
+	mov	\xreg1, #0x531
+#else
+	/* 64bit EL2 | HCE | SMD | RES1 (Bits[5:4]) | Non-secure EL0/EL1 */
+	mov	\xreg1, #0x5b1
+#endif
+	msr	scr_el3, \xreg1
+	msr	cptr_el3, xzr		/* Disable coprocessor traps to EL3 */
+	mov	\xreg1, #0x33ff
+	msr	cptr_el2, \xreg1	/* Disable coprocessor traps to EL2 */
+
+	/* Initialize SCTLR_EL2
+	 *
+	 * setting RES1 bits (29,28,23,22,18,16,11,5,4) to 1
+	 * and RES0 bits (31,30,27,26,24,21,20,17,15-13,10-6) +
+	 * EE,WXN,I,SA,C,A,M to 0
+	 */
+	mov	\xreg1, #0x0830
+	movk	\xreg1, #0x30C5, lsl #16
+	msr	sctlr_el2, \xreg1
+
+	/* Return to the EL2_SP2 mode from EL3 */
+	mov	\xreg1, sp
+	msr	sp_el2, \xreg1		/* Migrate SP */
+	mrs	\xreg1, vbar_el3
+	msr	vbar_el2, \xreg1	/* Migrate VBAR */
+	mov	\xreg1, #0x3c9
+	msr	spsr_el3, \xreg1	/* EL2_SP2 | D | A | I | F */
+	msr	elr_el3, lr
+	eret
+.endm
+
+.macro armv8_switch_to_el1_m, xreg1, xreg2
+	/* Initialize Generic Timers */
+	mrs	\xreg1, cnthctl_el2
+	orr	\xreg1, \xreg1, #0x3	/* Enable EL1 access to timers */
+	msr	cnthctl_el2, \xreg1
+	msr	cntvoff_el2, xzr
+
+	/* Initilize MPID/MPIDR registers */
+	mrs	\xreg1, midr_el1
+	mrs	\xreg2, mpidr_el1
+	msr	vpidr_el2, \xreg1
+	msr	vmpidr_el2, \xreg2
+
+	/* Disable coprocessor traps */
+	mov	\xreg1, #0x33ff
+	msr	cptr_el2, \xreg1	/* Disable coprocessor traps to EL2 */
+	msr	hstr_el2, xzr		/* Disable coprocessor traps to EL2 */
+	mov	\xreg1, #3 << 20
+	msr	cpacr_el1, \xreg1	/* Enable FP/SIMD at EL1 */
+
+	/* Initialize HCR_EL2 */
+	mov	\xreg1, #(1 << 31)		/* 64bit EL1 */
+	orr	\xreg1, \xreg1, #(1 << 29)	/* Disable HVC */
+	msr	hcr_el2, \xreg1
+
+	/* SCTLR_EL1 initialization
+	 *
+	 * setting RES1 bits (29,28,23,22,20,11) to 1
+	 * and RES0 bits (31,30,27,21,17,13,10,6) +
+	 * UCI,EE,EOE,WXN,nTWE,nTWI,UCT,DZE,I,UMA,SED,ITD,
+	 * CP15BEN,SA0,SA,C,A,M to 0
+	 */
+	mov	\xreg1, #0x0800
+	movk	\xreg1, #0x30d0, lsl #16
+	msr	sctlr_el1, \xreg1
+
+	/* Return to the EL1_SP1 mode from EL2 */
+	mov	\xreg1, sp
+	msr	sp_el1, \xreg1		/* Migrate SP */
+	mrs	\xreg1, vbar_el2
+	msr	vbar_el1, \xreg1	/* Migrate VBAR */
+	mov	\xreg1, #0x3c5
+	msr	spsr_el2, \xreg1	/* EL1_SP1 | D | A | I | F */
+	msr	elr_el2, lr
+	eret
+.endm
+
+#if defined(CONFIG_GICV3)
+.macro gic_wait_for_interrupt_m xreg1
+0 :	wfi
+	mrs     \xreg1, ICC_IAR1_EL1
+	msr     ICC_EOIR1_EL1, \xreg1
+	cbnz    \xreg1, 0b
+.endm
+#elif defined(CONFIG_GICV2)
+.macro gic_wait_for_interrupt_m xreg1, wreg2
+0 :	wfi
+	ldr     \wreg2, [\xreg1, GICC_AIAR]
+	str     \wreg2, [\xreg1, GICC_AEOIR]
+	and	\wreg2, \wreg2, #0x3ff
+	cbnz    \wreg2, 0b
+.endm
+#endif
+
+#endif /* CONFIG_ARM64 */
+
+#endif /* __ASSEMBLY__ */
+#endif /* __ASM_ARM_MACRO_H__ */
diff --git a/plat/marvell/a8k/a7040_rz/aarch64/plat_psci.S b/plat/marvell/a8k/a7040_rz/aarch64/plat_psci.S
new file mode 100644
index 0000000..82676af
--- /dev/null
+++ b/plat/marvell/a8k/a7040_rz/aarch64/plat_psci.S
@@ -0,0 +1,261 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2016 Marvell International Ltd.
+* ***************************************************************************
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are met:
+*
+* Redistributions of source code must retain the above copyright notice, this
+* list of conditions and the following disclaimer.
+*
+* Redistributions in binary form must reproduce the above copyright notice,
+* this list of conditions and the following disclaimer in the documentation
+* and/or other materials provided with the distribution.
+*
+* Neither the name of Marvell nor the names of its contributors may be used
+* to endorse or promote products derived from this software without specific
+* prior written permission.
+*
+* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+* AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+* IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+* ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+* LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
+* OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+* SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+* INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+* CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+* ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+* POSSIBILITY OF SUCH DAMAGE.
+*
+***************************************************************************
+*/
+/*
+ * Copyright (C) 2013 - ARM Ltd
+ * Author: Marc Zyngier <marc.zyngier@arm.com>
+ *
+ * Based on code by Carl van Schaik <carl@ok-labs.com>.
+ *
+ * Copyright (C) 2015 Marvell International Ltd.
+ *
+ * This program is free software: you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the Free
+ * Software Foundation, either version 2 of the License, or any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ * ***************************************************************************
+*/
+
+#include <plat_def.h>
+#include <asm/macro.h>
+
+#define MVEBU_CCU_HTC_ASET_REG	0x4264
+#define MVEBU_PRIVATE_UID_REG	0x30
+#define MVEBU_IO_AFFINITY		0xF00
+#define MVEBU_RFU_GLOBL_SW_RST	0x84
+#define ARM_PSCI_RET_SUCCESS	0
+
+.pushsection ._secure.text, "ax"
+
+/*******************************************************************************
+ * A8K cpu entry.
+ * This function implements WA of entry point alignment.
+ * A8K jump address (in SMP mode) must be alogned to 65KB. Since Linux jump
+ * address is not aliogned, this function is used and it will set the jump
+ * address which was passed to the CPU on SMC
+ ******************************************************************************/
+.global _armada8k_cpu_entry
+_armada8k_cpu_entry:
+	//b		.
+	/* get current CPU */
+	mrs 	x2, MPIDR_EL1   	/* get current CPU - Use affinity level 1 */
+	asr 	x2, x2, #8
+	and 	x2, x2, #0xff
+
+	/* set CPU private UID */
+	mov	x0, #(MVEBU_REGS_BASE)
+	add	x3, x0, #(MVEBU_PRIVATE_UID_REG)
+	add     x1, x2, #0x4
+	str 	w1, [x3]
+
+	bl	enable_affinity
+
+	isb
+
+	/*
+	 * Could be EL3/EL2/EL1, Initial State:
+	 * Little Endian, MMU Disabled, i/dCache Disabled
+	 */
+	//adr	x0, vectors		TODO - Get vector address from CPU0
+	//ldr	x0, =0x4029000 //EL3
+	ldr	x0, =0xFFFFFFC000084800 //EL1
+	switch_el x1, 3f, 2f, 1f
+3:	msr	vbar_el3, x0
+	mrs	x0, scr_el3
+	orr	x0, x0, #0xf			/* SCR_EL3.NS|IRQ|FIQ|EA */
+	msr	scr_el3, x0
+	msr	cptr_el3, xzr			/* Enable FP/SIMD */
+	ldr	x0, =COUNTER_FREQUENCY
+	msr	cntfrq_el0, x0			/* Initialize CNTFRQ */
+	b	0f
+2:	msr	vbar_el2, x0
+	mov	x0, #0x33ff
+	msr	cptr_el2, x0			/* Enable FP/SIMD */
+	b	0f
+1:	msr	vbar_el1, x0
+	mov	x0, #3 << 20
+	msr	cpacr_el1, x0			/* Enable FP/SIMD */
+0:
+
+#if defined(CONFIG_GICV3)
+	ldr	x0, =PLAT_MARVELL_GICR_BASE
+	bl	gic_init_secure_percpu
+#elif defined(CONFIG_GICV2)
+	ldr	x0, =PLAT_MARVELL_GICD_BASE
+	ldr	x1, =PLAT_MARVELL_GICC_BASE
+	bl	gic_init_secure_percpu
+#endif
+
+	bl	psci_build_stack
+
+	bl	armv8_switch_to_el2
+#ifdef CONFIG_ARMV8_SWITCH_TO_EL1
+	bl	armv8_switch_to_el1
+#endif
+
+	/* set linux start address - WA reset adderrs - use reserved register */
+	mov	x0, #(MVEBU_REGS_BASE)
+	mov     x2, #0x644
+	orr     x2, x2, x0
+	ldr     w0, [x2]
+
+	br	x0
+
+/*******************************************************************************
+ * This function saves Linux entry point which was passed by the SMC.
+ * It is required since ATF PSCI flow passed only the target CPU to CPU on
+ * routine. Therefore, the jump address should be saved before.
+ *
+ * Parameters:
+ * 		x0 = entry point
+ ******************************************************************************/
+.global psci_save_cpu_entrypoint
+psci_save_cpu_entrypoint:
+	adr	x2, _target_pc
+	str	x0, [x2]
+	ret
+
+.global enable_affinity
+enable_affinity:
+
+	/* get current CPU */
+	mrs 	x2, MPIDR_EL1   	/* get current CPU - Use affinity level 1 */
+	asr 	x2, x2, #8
+	and 	x2, x2, #0xff
+
+	/* Activate Affinity between current CPU */
+	mov	x0, #(MVEBU_REGS_BASE)
+	mov     x3, #(MVEBU_CCU_HTC_ASET_REG)
+	orr     x0, x3, x0
+	mov	x3, #0x1
+	lsl     x1, x3, x2
+	orr	x1, x1, #(MVEBU_IO_AFFINITY)
+	str     w1, [x0]
+#if 1 /* TODO - SMP enable stucks linux boot */
+	/* Activate Affinity in CA-57 configuration
+	 * Enable the SMPEN bit in CPUECTLR_EL1 */
+	mrs x0, S3_1_c15_c2_1
+	orr x0, x0, #0x40
+	msr S3_1_c15_c2_1, x0
+#endif
+	ret
+
+.globl	psci_arch_init
+psci_arch_init:
+	add	x29, x30, 0 /* keep return address */
+	bl	enable_affinity
+	bl	psci_build_stack
+#ifdef CONFIG_MVEBU_LLC_ENABLE
+	bl	llc_enable
+#endif
+	ret	x29
+
+psci_build_stack:
+
+	mrs     x5, SCR_EL3
+	bic	x5, x5, #1	/* Secure mode */
+	msr	SCR_EL3, x5
+	isb
+
+	mrs 	x4, MPIDR_EL1	/* get current CPU - Use affinity level 1 */
+	asr 	x4, x4, #8
+	and 	x4, x4, #0xff
+
+	mov	x5, #400		/* 1kB of stack per CPU */
+	mul	x4, x4, x5
+
+	adr	x5, text_end		/* end of text */
+	add	x5, x5, #0x2000		/* Skip two pages */
+	lsr	x5, x5, #12		/* Align to start of page */
+	lsl	x5, x5, #12
+	sub	sp, x5, x4		/* here's our stack! */
+
+	ret
+
+/* x0 = target CPU */
+.globl	psci_0_2_cpu_on_64
+psci_0_2_cpu_on_64:
+	mov 	x1, x0
+
+	dsb     sy
+
+	/* get cpu number - use affinity level 2 */
+	asr 	x1, x1, #8
+	and 	x1, x1, #0xff
+
+	/* set CPU private UID */
+	mov		x0, #(MVEBU_REGS_BASE)
+	add		x3, x0, #(MVEBU_PRIVATE_UID_REG)
+	add     x2, x1, #0x4
+	str 	w2, [x3]
+
+	/* set the cpu start address */
+	add	x3, x0, #0x640
+
+	/* CPU reset vector address - must be aligned to 0x10000
+	   first instruction - jump to _armada8k_cpu_entry */
+	adr     x2, _armada8k_cpu_entry
+	lsr	x2, x2, #16	/* align to 0x10000 */
+	str 	w2, [x3]
+
+	/* save the Linux out of reset address to unused register */
+	adr	x1, _target_pc
+	ldr	x1, [x1]
+	add	x3, x0, #0x644 /* WA reset adderrs - use reserved register */
+	str     w1, [x3]
+
+	/* get the cpu out of reset */
+	add	x3, x0, #0x650
+	movz 	x2, #0x1, LSL #16
+	add	x2, x2, #0x1
+	str 	w2, [x3]
+
+	/* return success */
+	mov	x0, #ARM_PSCI_RET_SUCCESS	/* Return PSCI_RET_SUCCESS */
+	ret
+
+	/* 64 bit alignment for elements accessed as data */
+	.align 4
+_target_pc:
+	.quad 0x0
+
+text_end:
+	.popsection
+
diff --git a/plat/marvell/a8k/a7040_rz/plat_pm.c b/plat/marvell/a8k/a7040_rz/plat_pm.c
new file mode 100644
index 0000000..24ab046
--- /dev/null
+++ b/plat/marvell/a8k/a7040_rz/plat_pm.c
@@ -0,0 +1,165 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2016 Marvell International Ltd.
+* ***************************************************************************
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are met:
+*
+* Redistributions of source code must retain the above copyright notice, this
+* list of conditions and the following disclaimer.
+*
+* Redistributions in binary form must reproduce the above copyright notice,
+* this list of conditions and the following disclaimer in the documentation
+* and/or other materials provided with the distribution.
+*
+* Neither the name of Marvell nor the names of its contributors may be used
+* to endorse or promote products derived from this software without specific
+* prior written permission.
+*
+* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+* AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+* IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+* ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+* LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
+* OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+* SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+* INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+* CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+* ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+* POSSIBILITY OF SUCH DAMAGE.
+*
+***************************************************************************
+*/
+
+#include <arch_helpers.h>
+#include <plat_marvell.h>
+#include <psci.h>
+#include <debug.h>
+
+
+extern void psci_0_2_cpu_on_64(u_register_t mpidr);
+extern void psci_save_cpu_entrypoint(uintptr_t entrypoint);
+
+/*******************************************************************************
+ * A8K handler called to check the validity of the power state
+ * parameter.
+ ******************************************************************************/
+int a8k_validate_power_state(unsigned int power_state,
+                            psci_power_state_t *req_state)
+{
+	ERROR("a8k_validate_power_state needs to be implemented\n");
+	panic();
+}
+
+/*******************************************************************************
+ * A8K handler called when a CPU is about to enter standby.
+ ******************************************************************************/
+void a8k_cpu_standby(plat_local_state_t cpu_state)
+{
+	ERROR("a8k_cpu_standby needs to be implemented\n");
+	panic();
+}
+
+/*******************************************************************************
+ * A8K handler called when a power domain is about to be turned on. The
+ * mpidr determines the CPU to be turned on.
+ ******************************************************************************/
+int a8k_pwr_domain_on(u_register_t mpidr)
+{
+	psci_0_2_cpu_on_64(mpidr);
+	return 0;
+}
+
+/*******************************************************************************
+ * A8K handler called to save the entry point which will be later on used
+ * when performing CPU on process.
+ ******************************************************************************/
+int a8k_validate_ns_entrypoint(uintptr_t entrypoint)
+{
+	psci_save_cpu_entrypoint(entrypoint);
+	return PSCI_E_SUCCESS;
+}
+
+
+/*******************************************************************************
+ * A8K handler called when a power domain is about to be turned off. The
+ * target_state encodes the power state that each level should transition to.
+ ******************************************************************************/
+void a8k_pwr_domain_off(const psci_power_state_t *target_state)
+{
+	ERROR("a8k_pwr_domain_off needs to be implemented\n");
+	panic();
+}
+
+/*******************************************************************************
+ * A8K handler called when a power domain is about to be suspended. The
+ * target_state encodes the power state that each level should transition to.
+ ******************************************************************************/
+void a8k_pwr_domain_suspend(const psci_power_state_t *target_state)
+{
+	ERROR("a8k_pwr_domain_suspend needs to be implemented\n");
+	panic();
+}
+
+/*******************************************************************************
+ * A8K handler called when a power domain has just been powered on after
+ * being turned off earlier. The target_state encodes the low power state that
+ * each level has woken up from.
+ ******************************************************************************/
+void a8k_pwr_domain_on_finish(const psci_power_state_t *target_state)
+{
+	ERROR("a8k_pwr_domain_on_finish needs to be implemented\n");
+	panic();
+}
+
+/*******************************************************************************
+ * A8K handler called when a power domain has just been powered on after
+ * having been suspended earlier. The target_state encodes the low power state
+ * that each level has woken up from.
+ * TODO: At the moment we reuse the on finisher and reinitialize the secure
+ * context. Need to implement a separate suspend finisher.
+ ******************************************************************************/
+void a8k_pwr_domain_suspend_finish(const psci_power_state_t *target_state)
+{
+	ERROR("a8k_pwr_domain_suspend_finish needs to be implemented\n");
+	panic();
+}
+
+/*******************************************************************************
+ * A8K handlers to shutdown/reboot the system
+ ******************************************************************************/
+static void __dead2 a8k_system_off(void)
+{
+	ERROR("a8k_system_off needs to be implemented\n");
+	panic();
+	wfi();
+	ERROR("A8K System Off: operation not handled.\n");
+	panic();
+}
+
+static void __dead2 a8k_system_reset(void)
+{
+	ERROR("a8k_system_reset needs to be implemented\n");
+	panic();
+	wfi();
+	ERROR("A8K System Reset: operation not handled.\n");
+	panic();
+}
+
+/*******************************************************************************
+ * Export the platform handlers via plat_arm_psci_pm_ops. The ARM Standard
+ * platform layer will take care of registering the handlers with PSCI.
+ ******************************************************************************/
+const plat_psci_ops_t plat_arm_psci_pm_ops = {
+	.cpu_standby = a8k_cpu_standby,
+	.pwr_domain_on = a8k_pwr_domain_on,
+	.pwr_domain_off = a8k_pwr_domain_off,
+	.pwr_domain_suspend = a8k_pwr_domain_suspend,
+	.pwr_domain_on_finish = a8k_pwr_domain_on_finish,
+	.pwr_domain_suspend_finish = a8k_pwr_domain_suspend_finish,
+	.system_off = a8k_system_off,
+	.system_reset = a8k_system_reset,
+	.validate_power_state = a8k_validate_power_state,
+	.validate_ns_entrypoint = a8k_validate_ns_entrypoint
+};
diff --git a/plat/marvell/a8k/a7040_rz/plat_topology.c b/plat/marvell/a8k/a7040_rz/plat_topology.c
new file mode 100644
index 0000000..bf72182
--- /dev/null
+++ b/plat/marvell/a8k/a7040_rz/plat_topology.c
@@ -0,0 +1,66 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2016 Marvell International Ltd.
+* ***************************************************************************
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are met:
+*
+* Redistributions of source code must retain the above copyright notice, this
+* list of conditions and the following disclaimer.
+*
+* Redistributions in binary form must reproduce the above copyright notice,
+* this list of conditions and the following disclaimer in the documentation
+* and/or other materials provided with the distribution.
+*
+* Neither the name of Marvell nor the names of its contributors may be used
+* to endorse or promote products derived from this software without specific
+* prior written permission.
+*
+* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+* AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+* IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+* ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+* LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
+* OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+* SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+* INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+* CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+* ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+* POSSIBILITY OF SUCH DAMAGE.
+*
+***************************************************************************
+*/
+
+
+#include <plat_marvell.h>
+
+/* Note: This file implements functions and structures which
+   are required by ATF build */
+
+const unsigned char arm_power_domain_tree_desc[] = {
+	/* No of root nodes */
+	MARVELL_CLUSTER_COUNT,
+	/* No of children for the first node */
+	PLAT_MARVELL_CLUSTER0_CORE_COUNT,
+	/* No of children for the second node */
+	PLAT_MARVELL_CLUSTER1_CORE_COUNT
+};
+
+
+/*******************************************************************************
+ * This function implements a part of the critical interface between the psci
+ * generic layer and the platform that allows the former to query the platform
+ * to convert an MPIDR to a unique linear index. An error code (-1) is returned
+ * in case the MPIDR is invalid.
+ ******************************************************************************/
+int plat_core_pos_by_mpidr(u_register_t mpidr)
+{
+	int target_id = mpidr / 0x100;
+
+	if (target_id < 1 || target_id > 3)
+		return -1;
+
+	return target_id;
+}
+
diff --git a/plat/marvell/common/aarch64/transition.S b/plat/marvell/common/aarch64/transition.S
new file mode 100644
index 0000000..006c033
--- /dev/null
+++ b/plat/marvell/common/aarch64/transition.S
@@ -0,0 +1,57 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2016 Marvell International Ltd.
+* ***************************************************************************
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are met:
+*
+* Redistributions of source code must retain the above copyright notice, this
+* list of conditions and the following disclaimer.
+*
+* Redistributions in binary form must reproduce the above copyright notice,
+* this list of conditions and the following disclaimer in the documentation
+* and/or other materials provided with the distribution.
+*
+* Neither the name of Marvell nor the names of its contributors may be used
+* to endorse or promote products derived from this software without specific
+* prior written permission.
+*
+* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+* AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+* IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+* ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+* LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
+* OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+* SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+* INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+* CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+* ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+* POSSIBILITY OF SUCH DAMAGE.
+*
+***************************************************************************
+*/
+/*
+ * (C) Copyright 2013
+ * David Feng <fenghua@phytium.com.cn>
+ *
+ * SPDX-License-Identifier:	GPL-2.0+
+ */
+
+#include <asm/linkage.h>
+#include <asm/macro.h>
+
+/* insert functions to secure section - part of the PSCI FW */
+.pushsection ._secure.text, "ax"
+
+ENTRY(armv8_switch_to_el2)
+	switch_el x0, 1f, 0f, 0f
+0:	ret
+1:	armv8_switch_to_el2_m x0
+ENDPROC(armv8_switch_to_el2)
+
+ENTRY(armv8_switch_to_el1)
+	switch_el x0, 0f, 1f, 0f
+0:	ret
+1:	armv8_switch_to_el1_m x0, x1
+ENDPROC(armv8_switch_to_el1)
diff --git a/plat/marvell/common/marvell_pm.c b/plat/marvell/common/marvell_pm.c
new file mode 100644
index 0000000..30f8a5b
--- /dev/null
+++ b/plat/marvell/common/marvell_pm.c
@@ -0,0 +1,51 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2016 Marvell International Ltd.
+* ***************************************************************************
+*
+* Redistribution and use in source and binary forms, with or without 
+* modification, are permitted provided that the following conditions are met:
+*
+* Redistributions of source code must retain the above copyright notice, this
+* list of conditions and the following disclaimer.
+*
+* Redistributions in binary form must reproduce the above copyright notice,
+* this list of conditions and the following disclaimer in the documentation
+* and/or other materials provided with the distribution.
+*
+* Neither the name of Marvell nor the names of its contributors may be used
+* to endorse or promote products derived from this software without specific
+* prior written permission.
+*
+* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+* AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+* IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+* ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+* LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, 
+* OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+* SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+* INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+* CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+* ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+* POSSIBILITY OF SUCH DAMAGE.
+*
+***************************************************************************
+*/
+
+#include <psci.h>
+
+/* Standard ARM platforms are expected to export plat_arm_psci_pm_ops */
+extern const plat_psci_ops_t plat_arm_psci_pm_ops;
+
+
+/*******************************************************************************
+ * The ARM Standard platform definition of platform porting API
+ * `plat_setup_psci_ops`.
+ ******************************************************************************/
+int plat_setup_psci_ops(uintptr_t sec_entrypoint,
+				const plat_psci_ops_t **psci_ops)
+{
+	*psci_ops = &plat_arm_psci_pm_ops;
+
+	return 0;
+}
diff --git a/plat/marvell/common/marvell_topology.c b/plat/marvell/common/marvell_topology.c
new file mode 100644
index 0000000..8a2caf1
--- /dev/null
+++ b/plat/marvell/common/marvell_topology.c
@@ -0,0 +1,56 @@
+/*
+ * Copyright (c) 2015, ARM Limited and Contributors. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ * Redistributions of source code must retain the above copyright notice, this
+ * list of conditions and the following disclaimer.
+ *
+ * Redistributions in binary form must reproduce the above copyright notice,
+ * this list of conditions and the following disclaimer in the documentation
+ * and/or other materials provided with the distribution.
+ *
+ * Neither the name of ARM nor the names of its contributors may be used
+ * to endorse or promote products derived from this software without specific
+ * prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <plat_marvell.h>
+
+
+/* Note: This file implements functions which
+   are required by ATF build */
+
+/* The power domain tree descriptor which need to be exported by ARM platforms */
+extern const unsigned char arm_power_domain_tree_desc[];
+
+/*******************************************************************************
+ * This function returns the ARM default topology tree information.
+ ******************************************************************************/
+const unsigned char *plat_get_power_domain_tree_desc(void)
+{
+	return arm_power_domain_tree_desc;
+}
+
+/*******************************************************************************
+ * This function validates an MPIDR by checking whether it falls within the
+ * acceptable bounds. An error code (-1) is returned if an incorrect mpidr
+ * is passed.
+ ******************************************************************************/
+int arm_check_mpidr(u_register_t mpidr)
+{
+	return 0;
+}
-- 
1.9.1

